{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf79395-0b89-4d9f-af2c-19950ace1c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from spacy.util import filter_spans \n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141d4fd1-546a-43b9-aa5d-2cc81bc0c164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'gs://doccano_annotation/data/preannoated_data_with_bioverbs.parquet'\n",
    "drop_labels = ['BIOVERB', 'CHEMICAL', 'CELL LINE', 'UNKNOWN']\n",
    "display = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0632d0c-968d-4e23-9920-99eb106c2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "def read_jsonl(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        json_list = list(f)\n",
    "    data = []\n",
    "    for j in json_list:\n",
    "        data.append(json.loads(j))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def read_parquet(data_path):\n",
    "    return pd.read_parquet(data_path)\n",
    "\n",
    "def doccano_doc_to_df(df):\n",
    "    data = df[['doccano_doc']].copy()\n",
    "    data['entities'] = data['doccano_doc'].apply(lambda x: x['entities'])\n",
    "    data['text'] = data['doccano_doc'].apply(lambda x: x['text'])\n",
    "    data['relations'] = data['doccano_doc'].apply(lambda x: x['relations'])\n",
    "    return data[['text', 'entities', 'relations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a5ef94-cdb5-4021-baf5-784ec2ad4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_path.split('.')[-1] == 'jsonl':\n",
    "    our_data = read_jsonl(data_path)\n",
    "elif data_path.split('.')[-1] == 'parquet':\n",
    "    our_data = read_parquet(data_path)\n",
    "    our_data = doccano_doc_to_df(our_data)\n",
    "else:\n",
    "    raise Error('Please provide jsonl or paquet format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d2a05a-b92e-445b-b0ef-2daece2d2612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Effects of phorbol esters on the evoked nor...</td>\n",
       "      <td>[{'end_offset': 28, 'id': 22692, 'label': 'CHE...</td>\n",
       "      <td>[{'from_id': 22699, 'to_id': 22700, 'type': 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polymorphisms in NFKB1 that diminish its expr...</td>\n",
       "      <td>[{'end_offset': 23, 'id': 22811, 'label': 'TAR...</td>\n",
       "      <td>[{'from_id': 22811, 'to_id': 22812, 'type': 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A rabbit brain beta-galactosidase catalyzes t...</td>\n",
       "      <td>[{'end_offset': 34, 'id': 22847, 'label': 'TAR...</td>\n",
       "      <td>[{'from_id': 22854, 'to_id': 22849, 'type': 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Saccharomyces cerevisiae CRY1 and CRY2 ge...</td>\n",
       "      <td>[{'end_offset': 34, 'id': 22942, 'label': 'TAR...</td>\n",
       "      <td>[{'from_id': 22946, 'to_id': 22942, 'type': 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The multifunctional cytokine interleukin-6 (I...</td>\n",
       "      <td>[{'end_offset': 29, 'id': 23054, 'label': 'TAR...</td>\n",
       "      <td>[{'from_id': 23054, 'to_id': 23060, 'type': 'r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   1 Effects of phorbol esters on the evoked nor...   \n",
       "1   Polymorphisms in NFKB1 that diminish its expr...   \n",
       "2   A rabbit brain beta-galactosidase catalyzes t...   \n",
       "3   The Saccharomyces cerevisiae CRY1 and CRY2 ge...   \n",
       "4   The multifunctional cytokine interleukin-6 (I...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [{'end_offset': 28, 'id': 22692, 'label': 'CHE...   \n",
       "1  [{'end_offset': 23, 'id': 22811, 'label': 'TAR...   \n",
       "2  [{'end_offset': 34, 'id': 22847, 'label': 'TAR...   \n",
       "3  [{'end_offset': 34, 'id': 22942, 'label': 'TAR...   \n",
       "4  [{'end_offset': 29, 'id': 23054, 'label': 'TAR...   \n",
       "\n",
       "                                           relations  \n",
       "0  [{'from_id': 22699, 'to_id': 22700, 'type': 'i...  \n",
       "1  [{'from_id': 22811, 'to_id': 22812, 'type': 'i...  \n",
       "2  [{'from_id': 22854, 'to_id': 22849, 'type': 'i...  \n",
       "3  [{'from_id': 22946, 'to_id': 22942, 'type': 'e...  \n",
       "4  [{'from_id': 23054, 'to_id': 23060, 'type': 'r...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b734a6-2f71-45db-bf5b-04512f668e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities labels :  ['CHEMICAL', 'CELL_LINE', 'TARGET', 'UNKNOWN', 'DISEASE', 'BIOVERB']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ad10_cb/opt/anaconda3/envs/spacy/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "ner_labels = our_data.entities.apply(lambda x: [x[i]['label'] for i in range(len(x))])\n",
    "print('Entities labels : ', list(set(np.sum([ner_labels.iloc[k] for k in range(ner_labels.shape[0])]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416e427f-22db-4242-a5fb-f5beb023b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relations labels :  ['!increas', '!reduc', 'activ', '!decreas', '!bind', '!express', 'bind', 'regul', '!block', 'induc', 'decreas', 'reduc', 'inhibit', 'increas', '!activ', '!regul', '!inhibit', 'express', 'block', '!induc']\n"
     ]
    }
   ],
   "source": [
    "classes = our_data.relations.apply(lambda x: [x[i]['type'] for i in range(len(x))])\n",
    "print('Relations labels : ', list(set(np.sum([classes.iloc[k] for k in range(classes.shape[0])]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab6d399-eb53-4b16-b460-c655b6ee3176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop labels that we are not interested in\n",
    "def drop_label(x, labels):\n",
    "    return [entity_dict for entity_dict in x if entity_dict['label'] not in labels]\n",
    "\n",
    "# Preprocess text input\n",
    "def preprocess_text(string):\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573f64a8-5e5d-49e9-9a60-9c4f3c1f1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens\n",
    "def get_tokens(x, i):\n",
    "    doc = x['doc'].copy()\n",
    "    text = str(doc[i])\n",
    "    start = doc[i:i+1].start_char\n",
    "    end = doc[i:i+1].end_char\n",
    "    return {'text': text, \n",
    "            'start': start, \n",
    "            'end': end, \n",
    "            'id': i, \n",
    "            'ws': True if end<len(x.text_preprocessed) else False,\n",
    "            'disabled': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7aaa65-23d7-4fef-95c1-a66d4e0c1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spans\n",
    "def get_spans(x):\n",
    "    spans = []\n",
    "    doc = x['doc'].copy()\n",
    "    for d in x.entities:\n",
    "        span = doc.char_span(d['start_offset'], d['end_offset'], d['label'], kb_id=d['id'])\n",
    "        if str(span)[-1] == ' ':\n",
    "            span = doc.char_span(d['start_offset'], d['end_offset']-1, d['label'], kb_id=d['id']) # delete ' ' at the beginning of the entity\n",
    "        if str(span)[0] == ' ':\n",
    "            span = doc.char_span(d['start_offset']+1, d['end_offset'], d['label'], kb_id=d['id']) # delete ' ' at the end of the entity\n",
    "        if span is not None:\n",
    "            spans.append(span)\n",
    "    filtered_spans = filter_spans(spans)\n",
    "    return [{'id': span.kb_id,\n",
    "            'text': str(span), \n",
    "            'start': span.start_char, \n",
    "            'token_start': span.start,\n",
    "            'token_end': span.end, \n",
    "            'end': span.end_char, \n",
    "            'type': 'span',\n",
    "            'label': span.label_}\n",
    "           for span in filtered_spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a762118-fa7a-4e7d-98ee-77b7636f5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relations\n",
    "def get_head_child_attributes(spans, head_entity, child_entity, label):\n",
    "    head_dicts = [span_dict for span_dict in spans if (span_dict['id']==head_entity)]\n",
    "    child_dicts = [span_dict for span_dict in spans if (span_dict['id']==child_entity)]\n",
    "\n",
    "    assert len(head_dicts) <= 1\n",
    "    assert len(child_dicts) <= 1\n",
    "\n",
    "    if (len(head_dicts) > 0) & (len(child_dicts) > 0):\n",
    "        head_start = head_dicts[0]['start']\n",
    "        head_end = head_dicts[0]['end']\n",
    "        head_token_start = head_dicts[0]['token_start']\n",
    "        head_token_end = head_dicts[0]['token_end']\n",
    "        head_label = head_dicts[0]['label']\n",
    "\n",
    "        child_start = child_dicts[0]['start']\n",
    "        child_end = child_dicts[0]['end']\n",
    "        child_token_start = child_dicts[0]['token_start']\n",
    "        child_token_end = child_dicts[0]['token_end']\n",
    "        child_label = child_dicts[0]['label']\n",
    "\n",
    "        head = head_token_end\n",
    "        child = child_token_end\n",
    "        label = label\n",
    "\n",
    "        relations_dict = {'head': head,\n",
    "                          'child': child,\n",
    "                          'head_span': {'start': head_start, \n",
    "                                       'end': head_end, \n",
    "                                       'token_start': head_token_start, \n",
    "                                       'token_end': head_token_end, \n",
    "                                       'label': head_label}, \n",
    "                            'child_span': {'start': child_start, \n",
    "                                       'end': child_end, \n",
    "                                       'token_start': child_token_start, \n",
    "                                       'token_end': child_token_end, \n",
    "                                       'label': child_label}, \n",
    "                            'label': label}\n",
    "    else:\n",
    "        relations_dict = {}\n",
    "    return relations_dict\n",
    "\n",
    "\n",
    "def get_relations(x, directed=True, add_no_rel=False):\n",
    "    relations_form = []\n",
    "    relations = x['relations'].copy()\n",
    "    spans = x['spans'].copy()\n",
    "    remaining_combinations = [(spans[i]['id'], spans[j]['id']) \n",
    "                        for i in range(len(spans))\n",
    "                        for j in range(len(spans))\n",
    "                        if spans[i]['id'] != spans[j]['id']]\n",
    "    for i in range(len(relations)):\n",
    "        head_entity = relations[i]['from_id'] \n",
    "        child_entity = relations[i]['to_id']\n",
    "        relations_dict = get_head_child_attributes(spans, head_entity, child_entity, x['relations'][i]['type'].split('!')[-1])\n",
    "        if relations_dict != {}:\n",
    "            relations_form.append(relations_dict)\n",
    "            if not directed:\n",
    "                relations_form.append(get_head_child_attributes(spans, child_entity, head_entity, \n",
    "                                                                x['relations'][i]['type'].split('!')[-1]))\n",
    "        try:\n",
    "            remaining_combinations.remove((head_entity, child_entity))\n",
    "            if not directed:\n",
    "                remaining_combinations.remove((child_entity, head_entity))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if add_no_rel:\n",
    "        for c in range(len(remaining_combinations)):\n",
    "            head_entity = remaining_combinations[c][0]\n",
    "            child_entity = remaining_combinations[c][1]\n",
    "            relations_dict = get_head_child_attributes(spans, head_entity, child_entity, 'No-Rel')\n",
    "            relations_form.append(relations_dict)\n",
    "    return relations_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0efa809-db4c-4e55-9474-06a308f4457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rows_no_rel(x):\n",
    "    to_drop = False\n",
    "    labels = [x['relations_form'][i]['label'] for i in range(len(x['relations_form']))]\n",
    "    if (list(set(labels)) == ['No-Rel']) or (len(labels) == 0):\n",
    "        to_drop = True\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2211d8-e87b-41d6-aebd-e2e703b8919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(our_data, drop_labels=[], directed=True, add_no_rel=False):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    nlp.tokenizer = Tokenizer(nlp.vocab, token_match=re.compile(r'\\S+').match)\n",
    "    if len(drop_labels) > 0:\n",
    "        our_data['entities'] = our_data['entities'].apply(lambda x: drop_label(x, drop_labels))\n",
    "    our_data['text_preprocessed'] = our_data['text'].str.lower()\n",
    "    our_data['doc'] = our_data['text_preprocessed'].apply(lambda x: nlp.make_doc(x))\n",
    "    our_data['tokens'] = our_data.apply(lambda x: [get_tokens(x, i) for i in range(len(x.doc))], axis=1)\n",
    "    our_data['spans'] = our_data.apply(lambda x: get_spans(x), axis=1)\n",
    "    our_data['relations_form'] = our_data.apply(lambda x: get_relations(x, \n",
    "                                                                        directed=directed, \n",
    "                                                                        add_no_rel=add_no_rel), \n",
    "                                                axis=1)\n",
    "    our_data['to_drop'] = our_data.apply(lambda x: delete_rows_no_rel(x), axis=1)\n",
    "    our_data = our_data[our_data.to_drop==False].copy()\n",
    "    our_data['answer'] = 'accept'\n",
    "    our_data['meta'] = None\n",
    "    our_data['meta'] = our_data['meta'].apply(lambda x: {'source': 'unkown'})\n",
    "    formatted_data = our_data[['text_preprocessed', 'spans', 'tokens', 'relations_form', 'answer', 'meta']]\n",
    "    formatted_data.columns = ['text', 'spans', 'tokens', 'relations', 'answer', 'meta']\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1934b1ea-c712-4abf-874f-9a17564cc8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formatted_data = preprocess(our_data, drop_labels=drop_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c44e5407-ef8f-4be3-a735-3013517cb9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        [{'id': 22811, 'text': 'nfkb1', 'start': 18, '...\n",
       "4        [{'id': 23054, 'text': 'multifunctional cytoki...\n",
       "6        [{'id': 23112, 'text': 'lrp5', 'start': 23, 't...\n",
       "20       [{'id': 24657, 'text': 'apetala2', 'start': 1,...\n",
       "24       [{'id': 24911, 'text': 'thrombin', 'start': 31...\n",
       "                               ...                        \n",
       "26000    [{'id': 1424994, 'text': 'anti-tumor necrosis ...\n",
       "26001    [{'id': 1425028, 'text': 'cbl-b', 'start': 31,...\n",
       "26002    [{'id': 1425045, 'text': 's-100 protein', 'sta...\n",
       "26004    [{'id': 1425186, 'text': 'labor', 'start': 41,...\n",
       "26005    [{'id': 1425218, 'text': 'tpo', 'start': 33, '...\n",
       "Name: spans, Length: 8500, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data.spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9133600a-716f-4c94-b8c5-987023956761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display spans\n",
    "from spacy import displacy\n",
    "\n",
    "def display_entities(text, entities, entity_type=None):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for entity in entities:\n",
    "        if (entity[\"label\"] == entity_type) or (entity_type is None):\n",
    "            span_start = entity[\"start\"]\n",
    "            span_end = entity[\"end\"]\n",
    "            label = entity[\"label\"]\n",
    "            ent = doc.char_span(span_start, span_end, label=label)\n",
    "            if ent is None:\n",
    "                continue\n",
    "            ents.append(ent)\n",
    "    doc.ents = ents\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "if display:\n",
    "    not_working = []\n",
    "    for k in range(formatted_data.shape[0]):\n",
    "        row = formatted_data.iloc[k]\n",
    "        try:\n",
    "            display_entities(row.text, row.spans, None)\n",
    "        except ValueError:\n",
    "            not_working.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd2a5e82-1f1e-46b1-aa9f-2462a604c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n1 = int(formatted_data.shape[0] * 65/100)\n",
    "n2 = int(formatted_data.shape[0] * 85/100) \n",
    "df_shuffled = formatted_data.sample(frac=1)\n",
    "annotations_train = df_shuffled[:n1]\n",
    "annotations_dev = df_shuffled[n1:n2]\n",
    "annotations_test = df_shuffled[n2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2627b015-78f5-4a84-a08d-18341d58c414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations_train.iloc[0].spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb3eb20-4307-40c6-be09-f0da3da4e8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations_train.iloc[0].relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77e3a104-555d-4a05-9b67-8806c767bff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 18,\n",
       "  'child': 22,\n",
       "  'head_span': {'start': 100,\n",
       "   'end': 106,\n",
       "   'token_start': 17,\n",
       "   'token_end': 18,\n",
       "   'label': 'DISEASE'},\n",
       "  'child_span': {'start': 126,\n",
       "   'end': 134,\n",
       "   'token_start': 21,\n",
       "   'token_end': 22,\n",
       "   'label': 'TARGET'},\n",
       "  'label': 'increas'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_train.iloc[0].relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65ed8c6c-cdab-4893-8d24-d3c55729223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(df, path):\n",
    "    our_jsonl = df.to_dict(orient='records')\n",
    "    with open(path, 'w') as outfile:\n",
    "        for json_line in our_jsonl:\n",
    "            json.dump(json_line, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f91035-d273-4ee4-90a5-4849c49f3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(annotations_train, '../NER/assets/annotations_train.jsonl')\n",
    "write_jsonl(annotations_dev, '../NER/assets/annotations_dev.jsonl')\n",
    "write_jsonl(annotations_test, '../NER/assets/annotations_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2193de2c-818e-456e-ae1c-e0ec302cf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(annotations_train, '../RE/assets/annotations_train.jsonl')\n",
    "write_jsonl(annotations_dev, '../RE/assets/annotations_dev.jsonl')\n",
    "write_jsonl(annotations_test, '../RE/assets/annotations_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d983a9a-9e48-46d8-be2b-aa5fdef1849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = annotations_test.relations.apply(lambda x: [x[i]['label'] for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4257dcb-2c96-4501-969b-9be67a7be612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ad10_cb/opt/anaconda3/envs/spacy/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "total_labels = list(np.sum([labels.iloc[k] for k in range(labels.shape[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfa26d5b-4638-433a-9816-b6a26f2bf981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activ 0.048323471400394474\n",
      "bind 0.019230769230769232\n",
      "block 0.05374753451676528\n",
      "decreas 0.10157790927021697\n",
      "express 0.08579881656804733\n",
      "increas 0.22830374753451677\n",
      "induc 0.15483234714003946\n",
      "inhibit 0.1222879684418146\n",
      "reduc 0.1203155818540434\n",
      "regul 0.0655818540433925\n"
     ]
    }
   ],
   "source": [
    "for label in np.unique(total_labels):\n",
    "    print(label, total_labels.count(label) / len(total_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255221d-011e-45a7-ac43-4d8b69cf00e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Pb : sur-représentation de la classe No-Rel\n",
    "\n",
    "Solutions possibles : \n",
    "\n",
    "    - Modifier la fonction de perte en pondérant le score en fonction de la classe\n",
    "    - Considérer des relations non dirigées : relations(head, child) = relation(child, head) ==> moins de No-Rel \n",
    "    - Concaténer deux modèles : cf https://doc.rero.ch/record/327157/files/cud_tci.pdf\n",
    "        - un premier modèle qui prédit l'absence de relation\n",
    "        - un deuxième qui prédit la classe de relation\n",
    "        \n",
    "        \n",
    "Remarque : \n",
    "- Pas de classe No-Rel !! Dans le modèle, on considère qu'il y a une relation A de e1 vers e2 ssi proba(A, e1, e2) > s=0.5. Si toutes les probas sont inférieures à s, alors pas de relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31349680-cd9d-4c79-9f2f-a83081b92f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_test = read_jsonl('../RE/assets/annotations_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b9bcfb-bfe4-42e4-b5ba-8331daec63d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twenty-four hours after vibration, muscle hyperalgesia was observed, concomitant to increased levels of il-6 in the gastrocnemius muscle and decreased expression of kv1.4 in the dorsal root ganglia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range()\n",
    "x = annotations_test.iloc[0]\n",
    "text = x.text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04d53f4-7771-4500-9df2-c6dc3cb62f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = [(x.spans[i]['start'], x.spans[i]['end'], x.spans[i]['label']) for i in range(len(x.spans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ab7f31-55f5-4eb3-9f69-194edf808dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35, 54, 'DISEASE'),\n",
       " (104, 108, 'TARGET'),\n",
       " (165, 170, 'TARGET'),\n",
       " (178, 197, 'TARGET')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "282e0b1e-8abf-459e-b4a9-ae6295bce594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 23,\n",
       "  'child': 6,\n",
       "  'head_span': {'start': 165,\n",
       "   'end': 170,\n",
       "   'token_start': 22,\n",
       "   'token_end': 23,\n",
       "   'label': 'TARGET'},\n",
       "  'child_span': {'start': 35,\n",
       "   'end': 54,\n",
       "   'token_start': 4,\n",
       "   'token_end': 6,\n",
       "   'label': 'DISEASE'},\n",
       "  'label': 'increas'},\n",
       " {'head': 28,\n",
       "  'child': 6,\n",
       "  'head_span': {'start': 178,\n",
       "   'end': 197,\n",
       "   'token_start': 25,\n",
       "   'token_end': 28,\n",
       "   'label': 'TARGET'},\n",
       "  'child_span': {'start': 35,\n",
       "   'end': 54,\n",
       "   'token_start': 4,\n",
       "   'token_end': 6,\n",
       "   'label': 'DISEASE'},\n",
       "  'label': 'increas'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3534836-cf8a-4d97-a913-8862695e5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d790f6f6-777a-4c79-9d58-dfc0c2e08ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insulin"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.char_span(*spans[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cf788-5f4b-44d3-9081-69020fffac14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
